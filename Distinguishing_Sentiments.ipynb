{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Provide a visualized summary of the sentiments expressed in Tweets sent out by the following news organizations: \n",
    "#BBC, CBS, CNN, Fox, and New York times.\n",
    "\n",
    "#Import tweepy, pandas, matplotlib, seaborn, textblob, vader\n",
    "\n",
    "#First plot will:\n",
    "    #be a scatter plot of sentiments of last 100 tweets\n",
    "    #Ranging from -1.0 to 1.0\n",
    "    #Scores of 0 is neutral sentiment\n",
    "    # -1 most negative sentiment\n",
    "    # +1 most positive sentiment\n",
    "    #Each plot point will reflect the compound sentiment of a tweet\n",
    "    #Sort each plot by a relative timestamp\n",
    "\n",
    "#Second plot will:\n",
    "    #be a bar plot visualizing OVERALL sentiments of last 100 tweets per org.\n",
    "    # Aggregate using VADER\n",
    "\n",
    "#Final must:\n",
    "    # Pull last 100 tweets per outlet\n",
    "    #Perform sentiment analysis: Compound, Positive, Neutral, Negative score per tweet\n",
    "    #Pull into a DataFrame the tweet's source account, it's text, date, sentiment scores\n",
    "    #Export the data from DataFrame into a CSV File\n",
    "    #Save png images per plot\n",
    "\n",
    "#Final Considerations:\n",
    "    #Use Matplotlib & Seaborn libraries\n",
    "    #Include a description of 3 observable trends\n",
    "    #Proper labeling of plots (titles, with date of analysis) and axes lables\n",
    "    #Exported markdown version of notebook called README.md in GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observable Trends:\n",
    "### 1:\n",
    "### 2:\n",
    "### 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies/Api Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "from pprint import pprint \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Twitter API Keys\n",
    "consumer_key = \"vbtDKBb6MLz1UDuXqjulinZWP\"\n",
    "consumer_secret = \"porfKt9UTtSp2XRYfqT7W5CaLAsgTFgXAgsjFYaAyxc42asmnw\"\n",
    "access_token = \"2503131714-U09cIrTKKguHgX4tLYxSIWFKqkpM3FCpko8huUm\"\n",
    "access_token_secret = \"QT9zEyQXvVzObM46BrIsx9kgqnwmZmhUjtNhafPU3iGcB\"\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target User Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBC Sentiment Scores\n",
      "---------------------------\n",
      "Compound Score: 0.4574\n",
      "Positive Score: 0.115\n",
      "Neutral Score: 0.885\n",
      "Negative Score: 0.0\n",
      "---------------------------\n",
      "End of BBC Scores\n",
      "---------------------------\n",
      "CBS Sentiment Scores\n",
      "---------------------------\n",
      "Compound Score: 0.6696\n",
      "Positive Score: 0.219\n",
      "Neutral Score: 0.781\n",
      "Negative Score: 0.0\n",
      "---------------------------\n",
      "End of CBS Scores\n",
      "---------------------------\n",
      "CNN Sentiment Scores\n",
      "---------------------------\n",
      "Compound Score: 0.6808\n",
      "Positive Score: 0.32\n",
      "Neutral Score: 0.68\n",
      "Negative Score: 0.0\n",
      "---------------------------\n",
      "End of CNN Scores\n",
      "---------------------------\n",
      "FOX Sentiment Scores\n",
      "---------------------------\n",
      "Compound Score: -0.4767\n",
      "Positive Score: 0.0\n",
      "Neutral Score: 0.819\n",
      "Negative Score: 0.181\n",
      "---------------------------\n",
      "End of FOX Scores\n",
      "---------------------------\n",
      "NYT Sentiment Scores\n",
      "---------------------------\n",
      "Compound Score: 0.0\n",
      "Positive Score: 0.0\n",
      "Neutral Score: 1.0\n",
      "Negative Score: 0.0\n",
      "---------------------------\n",
      "End of NYT Scores\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "#Target User Accounts\n",
    "bbc_user = \"@BBC\"\n",
    "cbs_user = \"@CBS\"\n",
    "cnn_user = \"@CNN\"\n",
    "fox_user = \"@FoxNews\"\n",
    "nyt_user = \"@nytimes\"\n",
    "\n",
    "#Assign Variables to hold sentiments for analysis\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []\n",
    "\n",
    "#Create a loop that evaulates 100 tweets (5 pages)\n",
    "for x in range(5):\n",
    "    \n",
    "    #Get all tweets from their home feed\n",
    "    bbc_tweets = api.user_timeline(bbc_user)\n",
    "    cbs_tweets = api.user_timeline(cbs_user)\n",
    "    cnn_tweets = api.user_timeline(cnn_user)\n",
    "    fox_tweets = api.user_timeline(fox_user)\n",
    "    nyt_tweets = api.user_timeline(nyt_user)\n",
    "    \n",
    "    #Loop through all the tweets\n",
    "    for tweet in bbc_tweets:\n",
    "        \n",
    "        #Run Vader Analysis on each tweet\n",
    "        compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "        pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "        neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "        neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "    \n",
    "    for tweet2 in cbs_tweets:\n",
    "        \n",
    "         #Run Vader Analysis on each tweet\n",
    "        compound2 = analyzer.polarity_scores(tweet2[\"text\"])[\"compound\"]\n",
    "        pos2 = analyzer.polarity_scores(tweet2[\"text\"])[\"pos\"]\n",
    "        neu2 = analyzer.polarity_scores(tweet2[\"text\"])[\"neu\"]\n",
    "        neg2 = analyzer.polarity_scores(tweet2[\"text\"])[\"neg\"]\n",
    "    \n",
    "    for tweet3 in cnn_tweets:\n",
    "        \n",
    "        #Run Vader Analysis on each tweet\n",
    "        compound3 = analyzer.polarity_scores(tweet3[\"text\"])[\"compound\"]\n",
    "        pos3 = analyzer.polarity_scores(tweet3[\"text\"])[\"pos\"]\n",
    "        neu3 = analyzer.polarity_scores(tweet3[\"text\"])[\"neu\"]\n",
    "        neg3 = analyzer.polarity_scores(tweet3[\"text\"])[\"neg\"]\n",
    "    \n",
    "    for tweet4 in fox_tweets:\n",
    "        \n",
    "         #Run Vader Analysis on each tweet\n",
    "        compound4 = analyzer.polarity_scores(tweet4[\"text\"])[\"compound\"]\n",
    "        pos4 = analyzer.polarity_scores(tweet4[\"text\"])[\"pos\"]\n",
    "        neu4 = analyzer.polarity_scores(tweet4[\"text\"])[\"neu\"]\n",
    "        neg4 = analyzer.polarity_scores(tweet4[\"text\"])[\"neg\"]\n",
    "    \n",
    "    for tweet5 in nyt_tweets:\n",
    "        \n",
    "         #Run Vader Analysis on each tweet\n",
    "        compound5 = analyzer.polarity_scores(tweet5[\"text\"])[\"compound\"]\n",
    "        pos5 = analyzer.polarity_scores(tweet5[\"text\"])[\"pos\"]\n",
    "        neu5 = analyzer.polarity_scores(tweet5[\"text\"])[\"neu\"]\n",
    "        neg5 = analyzer.polarity_scores(tweet5[\"text\"])[\"neg\"]\n",
    "        \n",
    "        \n",
    "#Add each sentiment value to the corresponding list:\n",
    "compound_list.append(compound)\n",
    "positive_list.append(pos)\n",
    "negative_list.append(neg)\n",
    "neutral_list.append(neu)\n",
    "#Print the averages\n",
    "print(\"BBC Sentiment Scores\")\n",
    "print(\"---------------------------\")\n",
    "# pprint(bbc_tweets)\n",
    "print(\"Compound Score: %s\" % compound)\n",
    "print(\"Positive Score: %s\" % pos)\n",
    "print(\"Neutral Score: %s\" % neu)\n",
    "print(\"Negative Score: %s\" % neg)\n",
    "print(\"---------------------------\")\n",
    "print(\"End of BBC Scores\")\n",
    "print(\"---------------------------\")\n",
    "\n",
    "#Print the averages\n",
    "print(\"CBS Sentiment Scores\")\n",
    "print(\"---------------------------\")\n",
    "# pprint(cbs_tweets)\n",
    "print(\"Compound Score: %s\" % compound2)\n",
    "print(\"Positive Score: %s\" % pos2)\n",
    "print(\"Neutral Score: %s\" % neu2)\n",
    "print(\"Negative Score: %s\" % neg2)\n",
    "print(\"---------------------------\")\n",
    "print(\"End of CBS Scores\")\n",
    "print(\"---------------------------\")\n",
    "\n",
    "#Print the averages\n",
    "print(\"CNN Sentiment Scores\")\n",
    "print(\"---------------------------\")\n",
    "# pprint(cnn_tweets)\n",
    "print(\"Compound Score: %s\" % compound3)\n",
    "print(\"Positive Score: %s\" % pos3)\n",
    "print(\"Neutral Score: %s\" % neu3)\n",
    "print(\"Negative Score: %s\" % neg3)\n",
    "print(\"---------------------------\")\n",
    "print(\"End of CNN Scores\")\n",
    "print(\"---------------------------\")\n",
    "\n",
    "#Print the averages\n",
    "print(\"FOX Sentiment Scores\")\n",
    "print(\"---------------------------\")\n",
    "# pprint(fox_tweets)\n",
    "print(\"Compound Score: %s\" % compound4)\n",
    "print(\"Positive Score: %s\" % pos4)\n",
    "print(\"Neutral Score: %s\" % neu4)\n",
    "print(\"Negative Score: %s\" % neg4)\n",
    "print(\"---------------------------\")\n",
    "print(\"End of FOX Scores\")\n",
    "print(\"---------------------------\")\n",
    "\n",
    "#Print the averages\n",
    "print(\"NYT Sentiment Scores\")\n",
    "print(\"---------------------------\")\n",
    "# pprint(nyt_tweets)\n",
    "print(\"Compound Score: %s\" % compound5)\n",
    "print(\"Positive Score: %s\" % pos5)\n",
    "print(\"Neutral Score: %s\" % neu5)\n",
    "print(\"Negative Score: %s\" % neg5)\n",
    "print(\"---------------------------\")\n",
    "print(\"End of NYT Scores\")\n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Twitter Sentiments DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
