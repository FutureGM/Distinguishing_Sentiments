{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opportunities for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#News Mood:\n",
    "\n",
    "#Setup a list of ALL news sources\n",
    "#News_source = [ , , , , ]\n",
    "#Setup empty dictionary\n",
    "#For x in range(5) \n",
    "# New loop for all news sources\n",
    "#For source in _news_source\n",
    "#___ -= api.user_timeline ( , )\n",
    "#For tweet in tweet\n",
    "#Convert dict to DF\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Provide a visualized summary of the sentiments expressed in Tweets sent out by the following news organizations: \n",
    "#BBC, CBS, CNN, Fox, and New York times.\n",
    "\n",
    "#Import tweepy, pandas, matplotlib, seaborn, textblob, vader\n",
    "\n",
    "#First plot will:\n",
    "    #be a scatter plot of sentiments of last 100 tweets\n",
    "    #Ranging from -1.0 to 1.0\n",
    "    #Scores of 0 is neutral sentiment\n",
    "    # -1 most negative sentiment\n",
    "    # +1 most positive sentiment\n",
    "    #Each plot point will reflect the compound sentiment of a tweet\n",
    "    #Sort each plot by a relative timestamp\n",
    "\n",
    "#Second plot will:\n",
    "    #be a bar plot visualizing OVERALL sentiments of last 100 tweets per org.\n",
    "    # Aggregate using VADER\n",
    "\n",
    "#Final must:\n",
    "    # Pull last 100 tweets per outlet\n",
    "    #Perform sentiment analysis: Compound, Positive, Neutral, Negative score per tweet\n",
    "    #Pull into a DataFrame the tweet's source account, it's text, date, sentiment scores\n",
    "    #Export the data from DataFrame into a CSV File\n",
    "    #Save png images per plot\n",
    "\n",
    "#Final Considerations:\n",
    "    #Use Matplotlib & Seaborn libraries\n",
    "    #Include a description of 3 observable trends\n",
    "    #Proper labeling of plots (titles, with date of analysis) and axes lables\n",
    "    #Exported markdown version of notebook called README.md in GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observable Trends:\n",
    "### 1:\n",
    "### 2:\n",
    "### 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies/Api Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "from pprint import pprint \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Twitter API Keys\n",
    "consumer_key = \"vbtDKBb6MLz1UDuXqjulinZWP\"\n",
    "consumer_secret = \"porfKt9UTtSp2XRYfqT7W5CaLAsgTFgXAgsjFYaAyxc42asmnw\"\n",
    "access_token = \"2503131714-U09cIrTKKguHgX4tLYxSIWFKqkpM3FCpko8huUm\"\n",
    "access_token_secret = \"QT9zEyQXvVzObM46BrIsx9kgqnwmZmhUjtNhafPU3iGcB\"\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target User Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBC Sentiment Scores\n",
      "---------------------------\n",
      "Compound Score: -0.5719\n",
      "Positive Score: 0.0\n",
      "Neutral Score: 0.701\n",
      "Negative Score: 0.299\n",
      "---------------------------\n",
      "End of BBC Scores\n",
      "---------------------------\n",
      "CBS Sentiment Scores\n",
      "---------------------------\n",
      "Compound Score: 0.0\n",
      "Positive Score: 0.0\n",
      "Neutral Score: 1.0\n",
      "Negative Score: 0.0\n",
      "---------------------------\n",
      "End of CBS Scores\n",
      "---------------------------\n",
      "CNN Sentiment Scores\n",
      "---------------------------\n",
      "Compound Score: 0.0\n",
      "Positive Score: 0.0\n",
      "Neutral Score: 1.0\n",
      "Negative Score: 0.0\n",
      "---------------------------\n",
      "End of CNN Scores\n",
      "---------------------------\n",
      "FOX Sentiment Scores\n",
      "---------------------------\n",
      "Compound Score: 0.3182\n",
      "Positive Score: 0.119\n",
      "Neutral Score: 0.881\n",
      "Negative Score: 0.0\n",
      "---------------------------\n",
      "End of FOX Scores\n",
      "---------------------------\n",
      "NYT Sentiment Scores\n",
      "---------------------------\n",
      "Compound Score: 0.4588\n",
      "Positive Score: 0.182\n",
      "Neutral Score: 0.818\n",
      "Negative Score: 0.0\n",
      "---------------------------\n",
      "End of NYT Scores\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "#Target User Accounts\n",
    "bbc_user = \"@BBCWorld\"\n",
    "cbs_user = \"@CBSNews\"\n",
    "cnn_user = \"@CNN\"\n",
    "fox_user = \"@FoxNews\"\n",
    "nyt_user = \"@nytimes\"\n",
    "\n",
    "#Assign Variables to hold sentiments for analysis\n",
    "# compound_list = []\n",
    "# positive_list = []\n",
    "# negative_list = []\n",
    "# neutral_list = []\n",
    "# tweet_list = []\n",
    "# dates_list = []\n",
    "\n",
    "# compound_list2 = []\n",
    "# positive_list2 = []\n",
    "# negative_list2 = []\n",
    "# neutral_list2 = []\n",
    "# tweet_list2 = []\n",
    "# dates_list2 = []\n",
    "\n",
    "# compound_list3 = []\n",
    "# positive_list3 = []\n",
    "# negative_list3 = []\n",
    "# neutral_list3 = []\n",
    "# tweet_list3 = []\n",
    "# dates_list3 = []\n",
    "\n",
    "# compound_list4 = []\n",
    "# positive_list4 = []\n",
    "# negative_list4 = []\n",
    "# neutral_list4 = []\n",
    "# tweet_list4 = []\n",
    "# dates_list4 = []\n",
    "\n",
    "# compound_list5 = []\n",
    "# positive_list5 = []\n",
    "# negative_list5 = []\n",
    "# neutral_list5 = []\n",
    "# tweet_list5 = []\n",
    "# dates_list5 = []\n",
    "\n",
    "# counter = 1\n",
    "# counter2 = 1\n",
    "# counter3 = 1\n",
    "# counter4 = 1\n",
    "# counter5 = 1\n",
    "# #Create a loop that evaulates 100 tweets (5 pages)\n",
    "# for x in range(5):\n",
    "    \n",
    "#     #Get all tweets from their home feed\n",
    "#     bbc_tweets = api.user_timeline(bbc_user)\n",
    "#     cbs_tweets = api.user_timeline(cbs_user)\n",
    "#     cnn_tweets = api.user_timeline(cnn_user)\n",
    "#     fox_tweets = api.user_timeline(fox_user)\n",
    "#     nyt_tweets = api.user_timeline(nyt_user)\n",
    "    \n",
    "#     #Loop through all the tweets\n",
    "#     for tweet in bbc_tweets:\n",
    "#         compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "#         pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "#         neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "#         neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "#         twe = counter, tweet[\"text\"]\n",
    "#         dte = tweet[\"created_at\"]\n",
    "#         counter = counter + 1\n",
    "#         tweets_ago = \n",
    "# #         print(\"Tweet#%s: %s\" % (counter,tweet[\"text\"]))\n",
    "# #Add each sentiment value to the corresponding list:\n",
    "#         compound_list.append(compound)\n",
    "#         positive_list.append(pos)\n",
    "#         negative_list.append(neg)\n",
    "#         neutral_list.append(neu)\n",
    "#         tweet_list.append(twe)\n",
    "#         dates_list.append(dte)\n",
    "        \n",
    "#     for tweet2 in cbs_tweets:\n",
    "        \n",
    "#         counter2 = counter2 + 1\n",
    "#          #Run Vader Analysis on each tweet\n",
    "#         compound2 = analyzer.polarity_scores(tweet2[\"text\"])[\"compound\"]\n",
    "#         pos2 = analyzer.polarity_scores(tweet2[\"text\"])[\"pos\"]\n",
    "#         neu2 = analyzer.polarity_scores(tweet2[\"text\"])[\"neu\"]\n",
    "#         neg2 = analyzer.polarity_scores(tweet2[\"text\"])[\"neg\"]\n",
    "#         twe2 = counter2, tweet2[\"text\"]\n",
    "#         dte2 = tweet2[\"created_at\"]\n",
    "#         tweetsAgo2 = counter2\n",
    "#         #Add each sentiment value to the corresponding list:\n",
    "#         compound_list2.append(compound2)\n",
    "#         positive_list2.append(pos2)\n",
    "#         negative_list2.append(neg2)\n",
    "#         neutral_list2.append(neu2)\n",
    "#         tweet_list2.append(twe2)\n",
    "#         dates_list2.append(dte2)\n",
    "\n",
    "#     for tweet3 in cnn_tweets:\n",
    "        \n",
    "#         counter3 = counter3 + 1\n",
    "#         #Run Vader Analysis on each tweet\n",
    "#         compound3 = analyzer.polarity_scores(tweet3[\"text\"])[\"compound\"]\n",
    "#         pos3 = analyzer.polarity_scores(tweet3[\"text\"])[\"pos\"]\n",
    "#         neu3 = analyzer.polarity_scores(tweet3[\"text\"])[\"neu\"]\n",
    "#         neg3 = analyzer.polarity_scores(tweet3[\"text\"])[\"neg\"]\n",
    "#         twe3 = counter3, tweet3[\"text\"]\n",
    "#         dte3 = tweet3[\"created_at\"]\n",
    "#         tweetsAgo3 = counter3\n",
    "#         #Add each sentiment value to the corresponding list:\n",
    "#         compound_list3.append(compound3)\n",
    "#         positive_list3.append(pos3)\n",
    "#         negative_list3.append(neg3)\n",
    "#         neutral_list3.append(neu3)\n",
    "#         tweet_list3.append(twe3)\n",
    "#         dates_list3.append(dte3)\n",
    "        \n",
    "#     for tweet4 in fox_tweets:\n",
    "        \n",
    "#         counter4 = counter4 + 1\n",
    "#          #Run Vader Analysis on each tweet\n",
    "#         compound4 = analyzer.polarity_scores(tweet4[\"text\"])[\"compound\"]\n",
    "#         pos4 = analyzer.polarity_scores(tweet4[\"text\"])[\"pos\"]\n",
    "#         neu4 = analyzer.polarity_scores(tweet4[\"text\"])[\"neu\"]\n",
    "#         neg4 = analyzer.polarity_scores(tweet4[\"text\"])[\"neg\"]\n",
    "#         twe4 = counter4, tweet4[\"text\"]\n",
    "#         dte4 = tweet4[\"created_at\"]\n",
    "#         tweetsAgo4 = counter4\n",
    "#         #Add each sentiment value to the corresponding list:\n",
    "#         compound_list4.append(compound4)\n",
    "#         positive_list4.append(pos4)\n",
    "#         negative_list4.append(neg4)\n",
    "#         neutral_list4.append(neu4)\n",
    "#         tweet_list4.append(twe4)\n",
    "#         dates_list4.append(dte4)\n",
    "\n",
    "#     for tweet5 in nyt_tweets:\n",
    "        \n",
    "#         counter5 = counter5 + 1\n",
    "#          #Run Vader Analysis on each tweet\n",
    "#         compound5 = analyzer.polarity_scores(tweet5[\"text\"])[\"compound\"]\n",
    "#         pos5 = analyzer.polarity_scores(tweet5[\"text\"])[\"pos\"]\n",
    "#         neu5 = analyzer.polarity_scores(tweet5[\"text\"])[\"neu\"]\n",
    "#         neg5 = analyzer.polarity_scores(tweet5[\"text\"])[\"neg\"]\n",
    "#         twe5 = counter5, tweet5[\"text\"]\n",
    "#         dte5 = tweet5[\"created_at\"]\n",
    "#         tweetsAgo5 = counter5\n",
    "#         #Add each sentiment value to the corresponding list:\n",
    "#         compound_list5.append(compound5)\n",
    "#         positive_list5.append(pos5)\n",
    "#         negative_list5.append(neg5)\n",
    "#         neutral_list5.append(neu5)\n",
    "#         tweet_list5.append(twe5)\n",
    "#         dates_list5.append(dte5)\n",
    "        \n",
    "# #Add each sentiment value to the corresponding list:\n",
    "# # compound_list.append(compound)\n",
    "# # positive_list.append(pos)\n",
    "# # negative_list.append(neg)\n",
    "# # neutral_list.append(neu)\n",
    "# # tweet_list.append(twe)\n",
    "# # dates_list.append(dte)\n",
    "\n",
    "# # compound_list2.append(compound2)\n",
    "# # positive_list2.append(pos2)\n",
    "# # negative_list2.append(neg2)\n",
    "# # neutral_list2.append(neu2)\n",
    "# # tweet_list2.append(twe2)\n",
    "# # dates_list2.append(dte2)\n",
    "\n",
    "# # compound_list3.append(compound3)\n",
    "# # positive_list3.append(pos3)\n",
    "# # negative_list3.append(neg3)\n",
    "# # neutral_list3.append(neu3)\n",
    "# # tweet_list3.append(twe3)\n",
    "# # dates_list3.append(dte3)\n",
    "\n",
    "# # compound_list4.append(compound4)\n",
    "# # positive_list4.append(pos4)\n",
    "# # negative_list4.append(neg4)\n",
    "# # neutral_list4.append(neu4)\n",
    "# # tweet_list4.append(twe4)\n",
    "# # dates_list4.append(dte4)\n",
    "\n",
    "# # compound_list5.append(compound5)\n",
    "# # positive_list5.append(pos5)\n",
    "# # negative_list5.append(neg5)\n",
    "# # neutral_list5.append(neu5)\n",
    "# # tweet_list5.append(twe5)\n",
    "# # dates_list5.append(dte5)\n",
    "\n",
    "# #Print the averages\n",
    "# print(\"BBC Sentiment Scores\")\n",
    "# print(\"---------------------------\")\n",
    "# # pprint(bbc_tweets)\n",
    "# print(\"Compound Score: %s\" % compound)\n",
    "# print(\"Positive Score: %s\" % pos)\n",
    "# print(\"Neutral Score: %s\" % neu)\n",
    "# print(\"Negative Score: %s\" % neg)\n",
    "# print(\"---------------------------\")\n",
    "# print(\"End of BBC Scores\")\n",
    "# print(\"---------------------------\")\n",
    "\n",
    "# #Print the averages\n",
    "# print(\"CBS Sentiment Scores\")\n",
    "# print(\"---------------------------\")\n",
    "# # pprint(cbs_tweets)\n",
    "# print(\"Compound Score: %s\" % compound2)\n",
    "# print(\"Positive Score: %s\" % pos2)\n",
    "# print(\"Neutral Score: %s\" % neu2)\n",
    "# print(\"Negative Score: %s\" % neg2)\n",
    "# print(\"---------------------------\")\n",
    "# print(\"End of CBS Scores\")\n",
    "# print(\"---------------------------\")\n",
    "\n",
    "# #Print the averages\n",
    "# print(\"CNN Sentiment Scores\")\n",
    "# print(\"---------------------------\")\n",
    "# # pprint(cnn_tweets)\n",
    "# print(\"Compound Score: %s\" % compound3)\n",
    "# print(\"Positive Score: %s\" % pos3)\n",
    "# print(\"Neutral Score: %s\" % neu3)\n",
    "# print(\"Negative Score: %s\" % neg3)\n",
    "# print(\"---------------------------\")\n",
    "# print(\"End of CNN Scores\")\n",
    "# print(\"---------------------------\")\n",
    "\n",
    "# #Print the averages\n",
    "# print(\"FOX Sentiment Scores\")\n",
    "# print(\"---------------------------\")\n",
    "# # pprint(fox_tweets)\n",
    "# print(\"Compound Score: %s\" % compound4)\n",
    "# print(\"Positive Score: %s\" % pos4)\n",
    "# print(\"Neutral Score: %s\" % neu4)\n",
    "# print(\"Negative Score: %s\" % neg4)\n",
    "# print(\"---------------------------\")\n",
    "# print(\"End of FOX Scores\")\n",
    "# print(\"---------------------------\")\n",
    "\n",
    "# #Print the averages\n",
    "# print(\"NYT Sentiment Scores\")\n",
    "# print(\"---------------------------\")\n",
    "# # pprint(nyt_tweets)\n",
    "# print(\"Compound Score: %s\" % compound5)\n",
    "# print(\"Positive Score: %s\" % pos5)\n",
    "# print(\"Neutral Score: %s\" % neu5)\n",
    "# print(\"Negative Score: %s\" % neg5)\n",
    "# print(\"---------------------------\")\n",
    "# print(\"End of NYT Scores\")\n",
    "# print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Kemerovo fire: Who are the victims in the Russia leisure centre blaze? https://t.co/tX0BjbjBtL'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test print to see if all tweets are captured and printed\n",
    "#     for tweet in bbc_tweets:\n",
    "        \n",
    "#         #Run Vader Analysis on each tweet\n",
    "#         compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "#         pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "#         neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "#         neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "#         twe = tweet[\"text\"]\n",
    "#         dte = tweet[\"created_at\"]\n",
    "        \n",
    "#         counter = counter + 1\n",
    "print(tweet[\"text\"].encode(\"UTF-8\"))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Twitter Sentiments DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@BBCWorld', '@CBSNews', '@CNN', '@FoxNews', '@nytimes']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = [bbc_user, cbs_user, cnn_user, fox_user, nyt_user]\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound</th>\n",
       "      <th>Date of Tweet</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Tweets Ago</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5095</td>\n",
       "      <td>Tue Mar 27 21:37:00 +0000 2018</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.202</td>\n",
       "      <td>(1, RT @BBCDanielS: BBC Exclusive interview wi...</td>\n",
       "      <td>42</td>\n",
       "      <td>@BBCWorld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>Tue Mar 27 21:20:33 +0000 2018</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(2, This 'smoking' elephant in India is baffli...</td>\n",
       "      <td>42</td>\n",
       "      <td>@BBCWorld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.2516</td>\n",
       "      <td>Tue Mar 27 20:14:24 +0000 2018</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.168</td>\n",
       "      <td>(3, Spy poisoning: 'I would really like to kno...</td>\n",
       "      <td>42</td>\n",
       "      <td>@BBCWorld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>Tue Mar 27 19:19:12 +0000 2018</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(4, Brazilian sports reporters tackle on-air g...</td>\n",
       "      <td>42</td>\n",
       "      <td>@BBCWorld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6705</td>\n",
       "      <td>Tue Mar 27 18:14:45 +0000 2018</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.332</td>\n",
       "      <td>(5, RT @BBCNews: Owl ring-bearer attacks best ...</td>\n",
       "      <td>42</td>\n",
       "      <td>@BBCWorld</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Compound                   Date of Tweet  Negative  Neutral  Positive  \\\n",
       "0    0.5095  Tue Mar 27 21:37:00 +0000 2018     0.000    0.798     0.202   \n",
       "1    0.0000  Tue Mar 27 21:20:33 +0000 2018     0.000    1.000     0.000   \n",
       "2   -0.2516  Tue Mar 27 20:14:24 +0000 2018     0.229    0.603     0.168   \n",
       "3    0.0000  Tue Mar 27 19:19:12 +0000 2018     0.000    1.000     0.000   \n",
       "4    0.6705  Tue Mar 27 18:14:45 +0000 2018     0.130    0.538     0.332   \n",
       "\n",
       "                                              Tweets  Tweets Ago       User  \n",
       "0  (1, RT @BBCDanielS: BBC Exclusive interview wi...          42  @BBCWorld  \n",
       "1  (2, This 'smoking' elephant in India is baffli...          42  @BBCWorld  \n",
       "2  (3, Spy poisoning: 'I would really like to kno...          42  @BBCWorld  \n",
       "3  (4, Brazilian sports reporters tackle on-air g...          42  @BBCWorld  \n",
       "4  (5, RT @BBCNews: Owl ring-bearer attacks best ...          42  @BBCWorld  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbcSentiments_DF = pd.DataFrame({\"Compound\": compound_list,\n",
    "                            \"Positive\": positive_list,\n",
    "                            \"Neutral\": neutral_list,\n",
    "                            \"Negative\": negative_list,\n",
    "                            \"Tweets\": tweet_list,\n",
    "                            \"Date of Tweet\": dates_list,\n",
    "                            \"User\": user[0],\n",
    "                            \"Tweets Ago\": tweets_ago})\n",
    "# bbcSentiments_DF.set_index(\"BBC User\", inplace=True)\n",
    "# print(\"BBC DataFrame\")\n",
    "bbc = bbcSentiments_DF\n",
    "bbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(bbc[\"Tweets\"])\n",
    "# print(\"Tweet#%s: %s\" % (counter,tweet[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cbsSentiments_DF = pd.DataFrame({\"Compound\": compound_list2,\n",
    "                            \"Positive\": positive_list2,\n",
    "                            \"Neutral\": neutral_list2,\n",
    "                            \"Negative\": negative_list2,\n",
    "                            \"Tweets\": tweet_list2,\n",
    "                            \"Date of Tweet\": dates_list2,\n",
    "                            \"User\": user[1],\n",
    "                            \"Tweets Ago\": tweetsAgo2})\n",
    "# cbsSentiments_DF.set_index(\"CBS User\", inplace=True)\n",
    "print(\"CBS DataFrame\")\n",
    "cbs = cbsSentiments_DF\n",
    "cbs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnnSentiments_DF = pd.DataFrame({\"Compound\": compound_list3,\n",
    "                            \"Positive\": positive_list3,\n",
    "                            \"Neutral\": neutral_list3,\n",
    "                            \"Negative\": negative_list3,\n",
    "                            \"Tweets\": tweet_list3,\n",
    "                            \"Date of Tweet\": dates_list3,\n",
    "                            \"User\": user[2],\n",
    "                            \"Tweets Ago\": tweetsAgo3})\n",
    "# cnnSentiments_DF.set_index(\"CNN User\", inplace=True)\n",
    "print(\"CNN DataFrame\")\n",
    "cnn = cnnSentiments_DF\n",
    "cnn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foxSentiments_DF = pd.DataFrame({\"Compound\": compound_list4,\n",
    "                            \"Positive\": positive_list4,\n",
    "                            \"Neutral\": neutral_list4,\n",
    "                            \"Negative\": negative_list4,\n",
    "                            \"Tweets\": tweet_list4,\n",
    "                            \"Date of Tweet\": dates_list4,\n",
    "                            \"User\": user[3],\n",
    "                            \"Tweets Ago\": tweetsAgo4})\n",
    "\n",
    "# foxSentiments_DF.set_index(\"Fox User\", inplace=True)\n",
    "print(\"Fox DataFrame\")\n",
    "fox = foxSentiments_DF\n",
    "fox.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nytSentiments_DF = pd.DataFrame({\"Compound\": compound_list5,\n",
    "                            \"Positive\": positive_list5,\n",
    "                            \"Neutral\": neutral_list5,\n",
    "                            \"Negative\": negative_list5,\n",
    "                            \"Tweets\": tweet_list5,\n",
    "                            \"Date of Tweet\": dates_list5,\n",
    "                            \"User\": user[4],\n",
    "                            \"Tweets Ago\": tweetsAgo5})\n",
    "# nytSentiments_DF.set_index(\"NYT User\", inplace=True)\n",
    "print(\"NYT DataFrame\")\n",
    "nyt = nytSentiments_DF\n",
    "nyt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Merging all DataFrames for Plotting:\n",
    "# # Trying Concatenating Objects\n",
    "\n",
    "# merge_DF = []\n",
    "# merge_DF = pd.concat(bbcSentiments_DF, \n",
    "#                     cbsSentiments_DF, \n",
    "#                     how='outer',\n",
    "#                     sort=True)\n",
    "\n",
    "# merge_DF = pd.merge(merge_DF,\n",
    "#                     cnnSentiments_DF,\n",
    "#                     how = \"outer\",\n",
    "#                     sort=True)\n",
    "\n",
    "# merge_DF = pd.merge(merge_DF,\n",
    "#                     foxSentiments_DF,\n",
    "#                     how = \"outer\",\n",
    "#                     sort=True)\n",
    "\n",
    "# merge_DF = pd.merge(merge_DF,\n",
    "#                     foxSentiments_DF,\n",
    "#                     how = \"outer\",\n",
    "#                     sort=True)\n",
    "\n",
    "# merge_DF = pd.merge(merge_DF,\n",
    "#                     nytSentiments_DF,\n",
    "#                     how = \"outer\",\n",
    "#                     sort=True)\n",
    "# # merge_DF.set_index(user, inplace=True)\n",
    "# # merge_DF = [bbc, cbs, cnn, fox, nyt]\n",
    "\n",
    "# # merge_results = pd.concat(merge_DF)\n",
    "# # merge_results.index = [\"BBC\", \"CBS\", \"CNN\", \"Fox\", \"NYT\"]\n",
    "# # merge_results\n",
    "# # merge_DF.set_index(\"User\", inplace=True)\n",
    "# # merge_DF.set_index\n",
    "# merge_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combine all dataframes through pd.concat\n",
    "merged_df = pd.concat([bbcSentiments_DF, cbsSentiments_DF, cnnSentiments_DF, foxSentiments_DF, nytSentiments_DF])\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter Plot Sentiment\n",
    "## Plot 1 Company at a Time (5 Plots) Before combining\n",
    "### Refer to Citipy Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bubble Plot\n",
    "# merge_Plot = merged_df[merged_df[\"User\"] == \"@BBCWorld\"]\n",
    "# # suburban_cities = merge_data[merge_data[\"type\"] == \"Suburban\"]\n",
    "# # rural_cities = merge_data[merge_data[\"type\"] == \"Rural\"]\n",
    "\n",
    "# merge_compound = merge_Plot.groupby([\"Date of Tweet\"]).count()[\"Compound\"]\n",
    "# merge_Tweets = merge_Plot.groupby([\"Date of Tweet\"]).count()[\"Tweets\"]\n",
    "# Tweet_Plot = pd.to_numeric(merge_Tweets)\n",
    "# Tweet_Compound = pd.to_numeric(merge_compound)\n",
    "# urban_avg_fare = urban_cities.groupby([\"city\"]).mean()[\"fare\"]\n",
    "# urban_drive_count = urban_cities.groupby([\"city\"]).mean()[\"driver_count\"]\n",
    "\n",
    "# suburban_ride_count = suburban_cities.groupby([\"city\"]).count()[\"ride_id\"]\n",
    "# suburban_avg_fare = suburban_cities.groupby([\"city\"]).mean()[\"fare\"]\n",
    "# suburban_drive_count = suburban_cities.groupby([\"city\"]).mean()[\"driver_count\"]\n",
    "\n",
    "# rural_ride_count = rural_cities.groupby([\"city\"]).count()[\"ride_id\"]\n",
    "# rural_avg_fare = rural_cities.groupby([\"city\"]).mean()[\"fare\"]\n",
    "# rural_drive_count = rural_cities.groupby([\"city\"]).mean()[\"driver_count\"]\n",
    "\n",
    "plt.scatter(x=bbcSentiments_DF[\"Tweets Ago\"],\n",
    "           y=bbcSentiments_DF[\"Compound\"],\n",
    "            facecolors=\"coral\",\n",
    "            edgecolor=\"black\", \n",
    "            linewidth=1, \n",
    "            marker='o',\n",
    "            alpha=0.8,\n",
    "            label=\"BBC\")\n",
    "\n",
    "plt.scatter(x=cbsSentiments_DF[\"Tweets Ago\"],\n",
    "           y=cbsSentiments_DF[\"Compound\"],\n",
    "            facecolors=\"coral\",\n",
    "            edgecolor=\"black\", \n",
    "            linewidth=1, \n",
    "            marker='o',\n",
    "            alpha=0.8,\n",
    "            label=\"CBS\")\n",
    "\n",
    "# plt.scatter(x=suburban_ride_count,\n",
    "#            y=suburban_avg_fare,\n",
    "#             s=15*suburban_drive_count, \n",
    "#             facecolors=\"skyblue\",\n",
    "#             edgecolor=\"black\", \n",
    "#             linewidth=1, \n",
    "#             marker='o',\n",
    "#             alpha=0.8) \n",
    "# #             label=\"Suburban\")\n",
    "\n",
    "# plt.scatter(x=rural_ride_count,\n",
    "#            y=rural_avg_fare,\n",
    "#             s=15*rural_drive_count, \n",
    "#             facecolors=\"gold\",\n",
    "#             edgecolor=\"black\", \n",
    "#             linewidth=1, \n",
    "#             marker='o',\n",
    "#             alpha=0.8) \n",
    "# #             label=\"Rural\")\n",
    "\n",
    "#Scatter Properties\n",
    "plt.title(\"Sentiment Analysis\")\n",
    "plt.ylabel(\"Tweet Sentiment Polarity\")\n",
    "plt.xlabel(\"Tweets Ago\")\n",
    "# plt.xlim((0,100))\n",
    "# plt.ylim((-1, 1))\n",
    "plt.legend((\"@BBCWorld\", ), numpoints=1, loc=\"upper right\", ncol=1, fontsize=8)\n",
    "#Create a Legend\n",
    "# lgn = plt.legend(fontsize='small', mode='Expanded', \n",
    "#                 numpoints=1, scatterpoints=1,\n",
    "#                 loc=\"beat\", title=\"City Types\",\n",
    "#                 labelspacing=0.5)\n",
    "# lgnd.legendHandles[0]._sizes = [30]\n",
    "# lgnd.legendHandles[1]._sizes = [30]\n",
    "# lgnd.legendHandles[2]._sizes = [30]\n",
    "\n",
    "# plt.text(42,35,\"Note:\\n Color correlates with Media Source.\")\n",
    "\n",
    "# plt.savefig(\"analysis/Fig.png\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      (11, .@NASCAR driver has words of grief for Io...\n",
      "1      (31, .@NASCAR driver has words of grief for Io...\n",
      "2      (51, .@NASCAR driver has words of grief for Io...\n",
      "3      (71, .@NASCAR driver has words of grief for Io...\n",
      "4      (91, .@NASCAR driver has words of grief for Io...\n",
      "5      (16, TOMORROW: 'Legends &amp; Lies' Returns Wi...\n",
      "6      (36, TOMORROW: 'Legends &amp; Lies' Returns Wi...\n",
      "7      (56, TOMORROW: 'Legends &amp; Lies' Returns Wi...\n",
      "8      (76, TOMORROW: 'Legends &amp; Lies' Returns Wi...\n",
      "9      (96, TOMORROW: 'Legends &amp; Lies' Returns Wi...\n",
      "10     (3, At Rallies, Students With a Different View...\n",
      "11     (23, At Rallies, Students With a Different Vie...\n",
      "12     (43, At Rallies, Students With a Different Vie...\n",
      "13     (63, At Rallies, Students With a Different Vie...\n",
      "14     (83, At Rallies, Students With a Different Vie...\n",
      "15     (14, \"For people who are watching ... know tha...\n",
      "16     (34, \"For people who are watching ... know tha...\n",
      "17     (54, \"For people who are watching ... know tha...\n",
      "18     (74, \"For people who are watching ... know tha...\n",
      "19     (94, \"For people who are watching ... know tha...\n",
      "20     (15, .@KayaJones on social media gun censorshi...\n",
      "21     (35, .@KayaJones on social media gun censorshi...\n",
      "22     (55, .@KayaJones on social media gun censorshi...\n",
      "23     (75, .@KayaJones on social media gun censorshi...\n",
      "24     (95, .@KayaJones on social media gun censorshi...\n",
      "25     (4, Native American women are running for offi...\n",
      "26     (24, Native American women are running for off...\n",
      "27     (44, Native American women are running for off...\n",
      "28     (64, Native American women are running for off...\n",
      "29     (84, Native American women are running for off...\n",
      "                             ...                        \n",
      "270    (19, .@RepMcSally: “You cannot have just one s...\n",
      "271    (39, .@RepMcSally: “You cannot have just one s...\n",
      "272    (59, .@RepMcSally: “You cannot have just one s...\n",
      "273    (79, .@RepMcSally: “You cannot have just one s...\n",
      "274    (99, .@RepMcSally: “You cannot have just one s...\n",
      "275    (9, Roxanne Shanté paved the way for female ra...\n",
      "276    (29, Roxanne Shanté paved the way for female r...\n",
      "277    (49, Roxanne Shanté paved the way for female r...\n",
      "278    (69, Roxanne Shanté paved the way for female r...\n",
      "279    (89, Roxanne Shanté paved the way for female r...\n",
      "280    (2, Earlier, Parkland survivor @Emma4Change ca...\n",
      "281    (22, Earlier, Parkland survivor @Emma4Change c...\n",
      "282    (42, Earlier, Parkland survivor @Emma4Change c...\n",
      "283    (62, Earlier, Parkland survivor @Emma4Change c...\n",
      "284    (82, Earlier, Parkland survivor @Emma4Change c...\n",
      "285    (3, Some of the most powerful signs from the M...\n",
      "286    (23, Some of the most powerful signs from the ...\n",
      "287    (43, Some of the most powerful signs from the ...\n",
      "288    (63, Some of the most powerful signs from the ...\n",
      "289    (83, Some of the most powerful signs from the ...\n",
      "290    (4, David Bossie on omnibus bill: \"The swamp w...\n",
      "291    (24, David Bossie on omnibus bill: \"The swamp ...\n",
      "292    (44, David Bossie on omnibus bill: \"The swamp ...\n",
      "293    (64, David Bossie on omnibus bill: \"The swamp ...\n",
      "294    (84, David Bossie on omnibus bill: \"The swamp ...\n",
      "295    (18, .@KellyannePolls on border wall: \"[Democr...\n",
      "296    (38, .@KellyannePolls on border wall: \"[Democr...\n",
      "297    (58, .@KellyannePolls on border wall: \"[Democr...\n",
      "298    (78, .@KellyannePolls on border wall: \"[Democr...\n",
      "299    (98, .@KellyannePolls on border wall: \"[Democr...\n",
      "Name: Tweets, Length: 300, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(merge_DF[\"Tweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = len(pd.Series(merge_results[\"Tweets\"][0]))\n",
    "pd.to_numeric(s, errors=\"coerce\")\n",
    "s = pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Make Tweets an int or flt value:\n",
    "# v = pd.value_counts(bbcSentiments_DF[\"Tweets\"])\n",
    "# print(v)\n",
    "bbcSentiments_DF = pd.converters={\"Tweets\": int}\n",
    "bbcSentiments_DF = pd.converters={\"Compound\": float}\n",
    "# print(type(bbcSentiments_DF[\"Compound\"]))\n",
    "# print(type(bbcSentiments_DF[\"Tweets\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert my data to numeric Values for Plotting\n",
    "# bbcSentiments_DF[\"Compound\"] = [float(val.replace(',', '')) for val in bbcSentiments_DF[\"Compound\"]]\n",
    "\n",
    "# X = str2double(bbcSentiments_DF[\"Compound\"])\n",
    "print(type(bbcSentiments_DF[\"Compound\"]))\n",
    "print(type(bbcSentiments_DF[\"Tweets\"]))\n",
    "#Use Exceptions:\n",
    "# try:\n",
    "#     return s.replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scatter plot build\n",
    "#Convert data columns \"Tweets\" and \"Compound\" to numeric to be useable\n",
    "bbcSentiments_DF[\"Compound\"] = pd.to_numeric(bbcSentiments_DF[\"Compound\"])\n",
    "bbcSentiments_DF[\"Tweets\"] = pd.to_numeric(bbcSentiments_DF[\"Tweets\"], errors=\"coerce\")\n",
    "\n",
    "print(type(bbcSentiments_DF[\"Compound\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Print Plot\n",
    "bbcSentiments_DF.plot(kind=\"scatter\", x=\"Tweets\", y=\"Compound\", grid=True, figsize=(20,10), \n",
    "                      title= \"Sentiments\")\n",
    "plt.ylabel(\"Sentiment Score\")\n",
    "plt.ylim(-1, 1)\n",
    "plt.xlabel(\"Tweets Over Time\")\n",
    "plt.xlim(0, 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First plot will:\n",
    "    #be a scatter plot of sentiments of last 100 tweets\n",
    "    #Ranging from -1.0 to 1.0\n",
    "    #Scores of 0 is neutral sentiment\n",
    "    # -1 most negative sentiment\n",
    "    # +1 most positive sentiment\n",
    "    #Each plot point will reflect the compound sentiment of a tweet\n",
    "    #Sort each plot by a relative timestamp\n",
    "\n",
    "#Build a scatter plot\n",
    "bbcSentiments_DF.plot(x=\"Tweets\", y=\"Compound\",kind=\"scatter\", ax=None)\n",
    "#Label Heading\n",
    "plt.title(\"Analysis of Sentiments of News Tweets\")\n",
    "\n",
    "#Axes labels and limits\n",
    "plt.ylabel(\"Sentiment Score\")\n",
    "plt.ylim(-1, 1)\n",
    "plt.xlabel(\"Tweets Over Time\")\n",
    "plt.xlim(0, 500)\n",
    "# x_axis = np.arange(0, s, 1)\n",
    "#Assemble Scatter Plot\n",
    "# plt.scatter(merge_DF[\"Tweets\"], \n",
    "#             merge_DF[\"Compound\"])\n",
    "\n",
    "#Show axis grids\n",
    "plt.grid(True)\n",
    "#Show legend\n",
    "plt.legend({\"BBC\"})\n",
    "#Save Plot\n",
    "plt.savefig(\"SentimentAnalysis.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar Graph of Overall Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Second plot will:\n",
    "    #be a bar plot visualizing OVERALL sentiments of last 100 tweets per org.\n",
    "    # Aggregate using VADER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set value for x-axis and tick_locations\n",
    "x_axis = np.arange(len(merge_results[\"Tweets\"]))\n",
    "tick_locations = [value + 0.4 for value in x_axis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#List where to write x labels and adjust figure size to fit\n",
    "plt.figure(figsize=(20,3))\n",
    "plt.bar(x_axis, merge_results[\"Compound\"])\n",
    "plt.xticks(tick_locations, merge_results[\"Compound\"], rotation=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set X and Y Limits:\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set Title and Labels\n",
    "plt.title(\"Twitter Sentiment Analysis\")\n",
    "plt.xlabel(\"Networks\")\n",
    "plt.ylabel(\"Sentiment Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save our graph and show\n",
    "plt.savefig(\"Sentiment_Bar_Scores.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
